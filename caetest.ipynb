{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bba0f84d",
   "metadata": {
    "papermill": {
     "duration": 0.009392,
     "end_time": "2022-05-05T13:45:18.164230",
     "exception": false,
     "start_time": "2022-05-05T13:45:18.154838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1. data loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15fc7df7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T13:45:18.181716Z",
     "iopub.status.busy": "2022-05-05T13:45:18.180927Z",
     "iopub.status.idle": "2022-05-05T13:45:23.031930Z",
     "shell.execute_reply": "2022-05-05T13:45:23.031183Z"
    },
    "papermill": {
     "duration": 4.862093,
     "end_time": "2022-05-05T13:45:23.034665",
     "exception": false,
     "start_time": "2022-05-05T13:45:18.172572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import img_to_array\n",
    "class loader:\n",
    "    def __init__(self):\n",
    "        self.x_data=[]\n",
    "        self.y_data=[]\n",
    "\n",
    "    def load(self,path):\n",
    "        files=os.listdir(path)\n",
    "        for i in files:\n",
    "            img=cv2.imread(path+'/'+i,cv2.IMREAD_GRAYSCALE)# 400 x 600\n",
    "            img=cv2.resize(img,(240,240))\n",
    "            #img=cv2.resize(img,(240,240))\n",
    "            #print(img.shape)\n",
    "            self.y_data.append(img_to_array(img))\n",
    "            self.x_data.append(img_to_array(img))\n",
    "        return self.x_data,self.y_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c2ddb6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T13:45:23.049931Z",
     "iopub.status.busy": "2022-05-05T13:45:23.049732Z",
     "iopub.status.idle": "2022-05-05T13:45:23.163310Z",
     "shell.execute_reply": "2022-05-05T13:45:23.161692Z"
    },
    "papermill": {
     "duration": 0.124337,
     "end_time": "2022-05-05T13:45:23.166316",
     "exception": false,
     "start_time": "2022-05-05T13:45:23.041979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "img=cv2.imread('../input/grid-map/111202511.png',cv2.IMREAD_GRAYSCALE)# 400 x 600\n",
    "img=cv2.resize(img,(240,240)) # 宽 x 高\n",
    "plt.imshow(img, cmap=plt.cm.gray)\n",
    "plt.xticks([])  # 去掉x轴\n",
    "plt.yticks([])  # 去掉y轴\n",
    "plt.axis('off')  # 去掉坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6a5c67b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T13:45:23.196370Z",
     "iopub.status.busy": "2022-05-05T13:45:23.196000Z",
     "iopub.status.idle": "2022-05-05T13:45:23.236407Z",
     "shell.execute_reply": "2022-05-05T13:45:23.235678Z"
    },
    "papermill": {
     "duration": 0.057689,
     "end_time": "2022-05-05T13:45:23.238639",
     "exception": false,
     "start_time": "2022-05-05T13:45:23.180950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Conv2D,UpSampling2D,MaxPooling2D\n",
    "from keras.layers import Input\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras import regularizers\n",
    "\n",
    "class Models:\n",
    "    def __init__(self,w,h,c):\n",
    "        self.w=w\n",
    "        self.h=h\n",
    "        self.c=c\n",
    "    def Arch1(self):\n",
    "        inp=Input(shape=(self.w,self.h,self.c))\n",
    "        enc=Conv2D(64,(3,3),padding='same')(inp)\n",
    "        enc=BatchNormalization()(enc)\n",
    "        enc=LeakyReLU(alpha=0.1)(enc)\n",
    "        enc=MaxPooling2D(pool_size=(2,2))(enc)\n",
    "        enc=Conv2D(32,(3,3),padding='same')(enc)\n",
    "        enc=LeakyReLU(alpha=0.1)(enc)\n",
    "        enc=BatchNormalization()(enc)\n",
    "        enc=MaxPooling2D(pool_size=(2,2))(enc)\n",
    "        enc=Conv2D(16,(3,3),padding='same')(enc)\n",
    "        enc=LeakyReLU(alpha=0.1)(enc)\n",
    "        enc=BatchNormalization()(enc)\n",
    "        enc=MaxPooling2D(pool_size=(2,2))(enc)\n",
    "        enc=Conv2D(8,(3,3),padding='same')(enc)\n",
    "        enc=LeakyReLU(alpha=0.1)(enc)\n",
    "        enc=MaxPooling2D(pool_size=(2,2))(enc)\n",
    "\n",
    "\n",
    "        dec=Conv2D(8,(3,3),padding='same')(enc)\n",
    "        dec=LeakyReLU(alpha=0.1)(dec)\n",
    "        dec=UpSampling2D((2,2))(dec)\n",
    "        dec=Conv2D(16,(3,3),padding='same')(dec)\n",
    "        dec=LeakyReLU(alpha=0.1)(dec)\n",
    "        dec=UpSampling2D((2,2))(dec)\n",
    "        dec=Conv2D(32,(3,3),padding='same')(dec)\n",
    "        dec=LeakyReLU(alpha=0.1)(dec)\n",
    "        dec=UpSampling2D((2,2))(dec)\n",
    "        dec=Conv2D(64,(3,3),padding='same')(dec)\n",
    "        dec=LeakyReLU(alpha=0.1)(dec)\n",
    "        dec=UpSampling2D((2,2))(dec)\n",
    "        final=Conv2D(1,(3,3),padding='same',activation='sigmoid')(dec)\n",
    "        auto=Model(inp,final)\n",
    "        return auto\n",
    "\n",
    "    def Arch2(self):\n",
    "        inp=Input(shape=(self.w,self.h,self.c))\n",
    "        enc=Conv2D(64,(3,3),padding='same',activity_regularizer=regularizers.l1(10e-5))(inp)\n",
    "        enc=BatchNormalization()(enc)\n",
    "        enc=LeakyReLU(alpha=0.1)(enc)\n",
    "        enc=MaxPooling2D(pool_size=(2,2))(enc)\n",
    "        enc=Conv2D(32,(3,3),padding='same',activity_regularizer=regularizers.l1(10e-5))(enc)\n",
    "        enc=LeakyReLU(alpha=0.1)(enc)\n",
    "        enc=BatchNormalization()(enc)\n",
    "        enc=MaxPooling2D(pool_size=(2,2))(enc)\n",
    "        enc=Conv2D(16,(3,3),padding='same',activity_regularizer=regularizers.l1(10e-5))(enc)\n",
    "        enc=LeakyReLU(alpha=0.1)(enc)\n",
    "        enc=BatchNormalization()(enc)\n",
    "        enc=MaxPooling2D(pool_size=(2,2),activity_regularizer=regularizers.l1(10e-5))(enc)\n",
    "        enc=Conv2D(8,(3,3),padding='same')(enc)\n",
    "        enc=LeakyReLU(alpha=0.1)(enc)\n",
    "        enc=MaxPooling2D(pool_size=(2,2))(enc)\n",
    "\n",
    "\n",
    "        dec=Conv2D(8,(3,3),padding='same',activity_regularizer=regularizers.l1(10e-5))(enc)\n",
    "        dec=LeakyReLU(alpha=0.1)(dec)\n",
    "        dec=UpSampling2D((2,2))(dec)\n",
    "        dec=Conv2D(16,(3,3),padding='same',activity_regularizer=regularizers.l1(10e-5))(dec)\n",
    "        dec=LeakyReLU(alpha=0.1)(dec)\n",
    "        dec=UpSampling2D((2,2))(dec)\n",
    "        dec=Conv2D(32,(3,3),padding='same',activity_regularizer=regularizers.l1(10e-5))(dec)\n",
    "        dec=LeakyReLU(alpha=0.1)(dec)\n",
    "        dec=UpSampling2D((2,2))(dec)\n",
    "        dec=Conv2D(64,(3,3),padding='same',activity_regularizer=regularizers.l1(10e-5))(dec)\n",
    "        dec=LeakyReLU(alpha=0.1)(dec)\n",
    "        dec=UpSampling2D((2,2))(dec)\n",
    "        final=Conv2D(1,(3,3),padding='same',activation='sigmoid')(dec)\n",
    "        auto=Model(inp,final)\n",
    "        return auto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771a1fe5",
   "metadata": {
    "papermill": {
     "duration": 0.010209,
     "end_time": "2022-05-05T13:45:23.262347",
     "exception": false,
     "start_time": "2022-05-05T13:45:23.252138",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## main 函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4bdc954",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T13:45:23.278191Z",
     "iopub.status.busy": "2022-05-05T13:45:23.277988Z",
     "iopub.status.idle": "2022-05-05T13:46:01.352281Z",
     "shell.execute_reply": "2022-05-05T13:46:01.351508Z"
    },
    "papermill": {
     "duration": 38.08623,
     "end_time": "2022-05-05T13:46:01.356002",
     "exception": false,
     "start_time": "2022-05-05T13:45:23.269772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import adam_v2\n",
    "\n",
    "w=240\n",
    "h=240\n",
    "c=1\n",
    "\n",
    "## 数据载入、训练集和测试集划分\n",
    "load_img=loader()\n",
    "x_data,y_data=load_img.load('../input/grid-map')\n",
    "x_data=np.array(x_data,dtype='float')/255.0\n",
    "y_data=np.array(y_data,dtype='float')/255.0\n",
    "train_x,test_x,train_y,test_y=train_test_split(x_data,y_data,test_size=0.1,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0e331ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T13:46:01.388411Z",
     "iopub.status.busy": "2022-05-05T13:46:01.388136Z",
     "iopub.status.idle": "2022-05-05T14:12:25.258625Z",
     "shell.execute_reply": "2022-05-05T14:12:25.257736Z"
    },
    "papermill": {
     "duration": 1583.889489,
     "end_time": "2022-05-05T14:12:25.261448",
     "exception": false,
     "start_time": "2022-05-05T13:46:01.371959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 13:46:01.508369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 13:46:01.615132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 13:46:01.616372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 13:46:01.619512: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-05 13:46:01.624623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 13:46:01.625673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 13:46:01.626744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 13:46:03.512784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 13:46:03.513931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 13:46:03.514791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-05 13:46:03.516110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 240, 240, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 240, 240, 64)      640       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 240, 240, 64)      256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 240, 240, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 120, 120, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 120, 120, 32)      18464     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 120, 120, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 120, 120, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 60, 60, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 16)        4624      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 60, 60, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 60, 60, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 8)         1160      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 30, 30, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 15, 8)         584       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 15, 15, 8)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 30, 30, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 16)        1168      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 60, 60, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 60, 60, 32)        4640      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 60, 60, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 120, 120, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 120, 120, 64)      18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 120, 120, 64)      0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 240, 240, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 240, 240, 1)       577       \n",
      "=================================================================\n",
      "Total params: 50,801\n",
      "Trainable params: 50,577\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 13:46:04.340121: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 748569600 exceeds 10% of free system memory.\n",
      "2022-05-05 13:46:05.704804: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 748569600 exceeds 10% of free system memory.\n",
      "2022-05-05 13:46:06.664335: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 748569600 exceeds 10% of free system memory.\n",
      "2022-05-05 13:46:07.193172: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 748569600 exceeds 10% of free system memory.\n",
      "2022-05-05 13:46:07.786666: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 13:46:09.620269: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "813/813 [==============================] - 23s 20ms/step - loss: 78.3137 - val_loss: 65.0992\n",
      "Epoch 2/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 57.4094 - val_loss: 49.5244\n",
      "Epoch 3/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 43.7214 - val_loss: 39.0201\n",
      "Epoch 4/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 35.6699 - val_loss: 32.7424\n",
      "Epoch 5/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 30.5542 - val_loss: 28.5869\n",
      "Epoch 6/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 26.7121 - val_loss: 25.0850\n",
      "Epoch 7/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 23.5525 - val_loss: 22.2666\n",
      "Epoch 8/100\n",
      "813/813 [==============================] - 16s 19ms/step - loss: 20.9142 - val_loss: 19.8939\n",
      "Epoch 9/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 18.7745 - val_loss: 17.9693\n",
      "Epoch 10/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 17.0507 - val_loss: 16.4325\n",
      "Epoch 11/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 15.6383 - val_loss: 15.1233\n",
      "Epoch 12/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 14.4689 - val_loss: 14.1802\n",
      "Epoch 13/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 13.5586 - val_loss: 13.3793\n",
      "Epoch 14/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 12.8710 - val_loss: 12.7590\n",
      "Epoch 15/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 12.3436 - val_loss: 12.1874\n",
      "Epoch 16/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 11.9312 - val_loss: 11.8446\n",
      "Epoch 17/100\n",
      "813/813 [==============================] - 16s 19ms/step - loss: 11.5734 - val_loss: 11.4359\n",
      "Epoch 18/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 11.2560 - val_loss: 11.1361\n",
      "Epoch 19/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 10.9608 - val_loss: 10.7549\n",
      "Epoch 20/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 10.7002 - val_loss: 10.5214\n",
      "Epoch 21/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 10.4654 - val_loss: 10.3102\n",
      "Epoch 22/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 10.2433 - val_loss: 10.0734\n",
      "Epoch 23/100\n",
      "813/813 [==============================] - 16s 19ms/step - loss: 10.0305 - val_loss: 9.8795\n",
      "Epoch 24/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 9.8305 - val_loss: 9.6754\n",
      "Epoch 25/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 9.6368 - val_loss: 9.4865\n",
      "Epoch 26/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 9.4499 - val_loss: 9.3004\n",
      "Epoch 27/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 9.2698 - val_loss: 9.1225\n",
      "Epoch 28/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 9.0965 - val_loss: 8.9573\n",
      "Epoch 29/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 8.9380 - val_loss: 8.8115\n",
      "Epoch 30/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 8.7879 - val_loss: 8.6749\n",
      "Epoch 31/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 8.6456 - val_loss: 8.5280\n",
      "Epoch 32/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 8.5109 - val_loss: 8.3936\n",
      "Epoch 33/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 8.3825 - val_loss: 8.2758\n",
      "Epoch 34/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 8.2567 - val_loss: 8.1327\n",
      "Epoch 35/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 8.1354 - val_loss: 8.0243\n",
      "Epoch 36/100\n",
      "813/813 [==============================] - 16s 19ms/step - loss: 8.0142 - val_loss: 7.8910\n",
      "Epoch 37/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 7.8964 - val_loss: 7.7886\n",
      "Epoch 38/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 7.7843 - val_loss: 7.6804\n",
      "Epoch 39/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 7.6774 - val_loss: 7.5824\n",
      "Epoch 40/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 7.5763 - val_loss: 7.4651\n",
      "Epoch 41/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 7.4813 - val_loss: 7.3840\n",
      "Epoch 42/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 7.3911 - val_loss: 7.2854\n",
      "Epoch 43/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 7.3003 - val_loss: 7.2014\n",
      "Epoch 44/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 7.2158 - val_loss: 7.1170\n",
      "Epoch 45/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 7.1316 - val_loss: 7.0492\n",
      "Epoch 46/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 7.0517 - val_loss: 6.9499\n",
      "Epoch 47/100\n",
      "813/813 [==============================] - 16s 19ms/step - loss: 6.9738 - val_loss: 6.8663\n",
      "Epoch 48/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 6.9001 - val_loss: 6.8060\n",
      "Epoch 49/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 6.8263 - val_loss: 6.7288\n",
      "Epoch 50/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 6.7561 - val_loss: 6.6553\n",
      "Epoch 51/100\n",
      "813/813 [==============================] - 16s 19ms/step - loss: 6.6854 - val_loss: 6.5836\n",
      "Epoch 52/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 6.6161 - val_loss: 6.5172\n",
      "Epoch 53/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 6.5500 - val_loss: 6.4459\n",
      "Epoch 54/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 6.4843 - val_loss: 6.3830\n",
      "Epoch 55/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 6.4195 - val_loss: 6.3255\n",
      "Epoch 56/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 6.3564 - val_loss: 6.2496\n",
      "Epoch 57/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 6.2930 - val_loss: 6.1898\n",
      "Epoch 58/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 6.2329 - val_loss: 6.1486\n",
      "Epoch 59/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 6.1729 - val_loss: 6.0843\n",
      "Epoch 60/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 6.1155 - val_loss: 6.0257\n",
      "Epoch 61/100\n",
      "813/813 [==============================] - 16s 19ms/step - loss: 6.0580 - val_loss: 5.9649\n",
      "Epoch 62/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 6.0027 - val_loss: 5.9054\n",
      "Epoch 63/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 5.9468 - val_loss: 5.8574\n",
      "Epoch 64/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 5.8925 - val_loss: 5.8102\n",
      "Epoch 65/100\n",
      "813/813 [==============================] - 16s 19ms/step - loss: 5.8385 - val_loss: 5.7387\n",
      "Epoch 66/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 5.7856 - val_loss: 5.7027\n",
      "Epoch 67/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 5.7311 - val_loss: 5.6429\n",
      "Epoch 68/100\n",
      "813/813 [==============================] - 15s 18ms/step - loss: 5.6775 - val_loss: 5.5918\n",
      "Epoch 69/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 5.6257 - val_loss: 5.5394\n",
      "Epoch 70/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 5.5745 - val_loss: 5.4830\n",
      "Epoch 71/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 5.5262 - val_loss: 5.4484\n",
      "Epoch 72/100\n",
      "813/813 [==============================] - 15s 19ms/step - loss: 5.4786 - val_loss: 5.3864\n",
      "Epoch 73/100\n",
      "813/813 [==============================] - 16s 19ms/step - loss: 5.4313 - val_loss: 5.3348\n",
      "Epoch 74/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 5.3852 - val_loss: 5.2922\n",
      "Epoch 75/100\n",
      "813/813 [==============================] - 17s 20ms/step - loss: 5.3374 - val_loss: 5.2553\n",
      "Epoch 76/100\n",
      "813/813 [==============================] - 16s 19ms/step - loss: 5.2940 - val_loss: 5.2157\n",
      "Epoch 77/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 5.2499 - val_loss: 5.1629\n",
      "Epoch 78/100\n",
      "813/813 [==============================] - 17s 21ms/step - loss: 5.2045 - val_loss: 5.1259\n",
      "Epoch 79/100\n",
      "813/813 [==============================] - 19s 23ms/step - loss: 5.1605 - val_loss: 5.0956\n",
      "Epoch 80/100\n",
      "813/813 [==============================] - 17s 20ms/step - loss: 5.1170 - val_loss: 5.0234\n",
      "Epoch 81/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 5.0726 - val_loss: 4.9940\n",
      "Epoch 82/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 5.0299 - val_loss: 4.9460\n",
      "Epoch 83/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 4.9868 - val_loss: 4.9020\n",
      "Epoch 84/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 4.9441 - val_loss: 4.8574\n",
      "Epoch 85/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 4.9019 - val_loss: 4.8102\n",
      "Epoch 86/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 4.8612 - val_loss: 4.7735\n",
      "Epoch 87/100\n",
      "813/813 [==============================] - 18s 22ms/step - loss: 4.8189 - val_loss: 4.7398\n",
      "Epoch 88/100\n",
      "813/813 [==============================] - 17s 21ms/step - loss: 4.7777 - val_loss: 4.6972\n",
      "Epoch 89/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 4.7367 - val_loss: 4.6466\n",
      "Epoch 90/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 4.6963 - val_loss: 4.6130\n",
      "Epoch 91/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 4.6573 - val_loss: 4.5755\n",
      "Epoch 92/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 4.6182 - val_loss: 4.5466\n",
      "Epoch 93/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 4.5792 - val_loss: 4.4923\n",
      "Epoch 94/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 4.5424 - val_loss: 4.4720\n",
      "Epoch 95/100\n",
      "813/813 [==============================] - 17s 21ms/step - loss: 4.5042 - val_loss: 4.4282\n",
      "Epoch 96/100\n",
      "813/813 [==============================] - 17s 21ms/step - loss: 4.4694 - val_loss: 4.3803\n",
      "Epoch 97/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 4.4334 - val_loss: 4.3430\n",
      "Epoch 98/100\n",
      "813/813 [==============================] - 16s 19ms/step - loss: 4.3972 - val_loss: 4.3065\n",
      "Epoch 99/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 4.3617 - val_loss: 4.2801\n",
      "Epoch 100/100\n",
      "813/813 [==============================] - 16s 20ms/step - loss: 4.3273 - val_loss: 4.2632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 14:12:22.584344: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "## 模型载入\n",
    "model=Models(w,h,c)\n",
    "auto_encoder=model.Arch2()\n",
    "auto_encoder.summary()\n",
    "\n",
    "auto_encoder.compile(optimizer='adadelta',loss='binary_crossentropy')\n",
    "auto_encoder.fit(train_x,train_y,batch_size=4,shuffle='true',epochs=100,validation_data=(test_x,test_y),verbose=1)\n",
    "auto_encoder.save('noise.MODEL')\n",
    "\n",
    "opt=adam_v2.Adam(learning_rate=0.002,decay=0.002/50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d9411",
   "metadata": {
    "papermill": {
     "duration": 9.661506,
     "end_time": "2022-05-05T14:12:45.238680",
     "exception": false,
     "start_time": "2022-05-05T14:12:35.577174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1667.607945,
   "end_time": "2022-05-05T14:12:58.026063",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-05T13:45:10.418118",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
